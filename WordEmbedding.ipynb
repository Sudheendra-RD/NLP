{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbedding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmRFbkFu1a4s/Kvq6GY8JV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudheendra-RD/NLP/blob/main/WordEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O7Kjb533iGJ6"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from tensorflow.keras.preprocessing.text import one_hot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = ['the glass of milk',\n",
        "        'the glass of juice',\n",
        "        'the cup of tea',\n",
        "        'I am a good boy',\n",
        "        'I am a good developer',\n",
        "        'understand the meaning of words',\n",
        "        'your videos are good']"
      ],
      "metadata": {
        "id": "kLMk7FugjVHr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary size\n",
        "voc_size = 10000"
      ],
      "metadata": {
        "id": "2ZpuMuQcsHr8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onehot_repr = [one_hot(words, voc_size) for words in sent]\n",
        "print(onehot_repr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVsQl_9PscG0",
        "outputId": "fe989009-fcaf-45f6-ff75-e5c6e89253d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5771, 9952, 7767, 906], [5771, 9952, 7767, 3731], [5771, 4973, 7767, 7518], [1144, 4822, 96, 5948, 8916], [1144, 4822, 96, 5948, 3865], [4991, 5771, 952, 7767, 1254], [5948, 7795, 7430, 5948]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "NbclrWc-s9Dj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "GIqQgkMFt6-u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Embedding or LSTM works best when the length of sentences is same\n",
        "# But here we have 4 words in some case and 5 in other case\n",
        "# so we add a function called pad_sequence to make the length of input same\n",
        "# This is like padding in CNN, adding 0's to make the process efficient"
      ],
      "metadata": {
        "id": "88Z4m9ext-eT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 2 types of padding, 'pre' and 'post'\n",
        "# Pre is used when we want to add padding in the beginning\n",
        "# Post is used when we want to add padding at the end\n",
        "# 'maxlen' is the length of each sentence after padding"
      ],
      "metadata": {
        "id": "_b233j_dvZWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded = pad_sequences(onehot_repr, padding='pre', maxlen=8)\n",
        "print(embedded)\n",
        "\n",
        "# Here we have given 'pre' padding and maxlen of 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5UQv1SbvIGt",
        "outputId": "ec0450ea-0fc2-4d7a-d03e-b0179deb70ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0 5771 9952 7767  906]\n",
            " [   0    0    0    0 5771 9952 7767 3731]\n",
            " [   0    0    0    0 5771 4973 7767 7518]\n",
            " [   0    0    0 1144 4822   96 5948 8916]\n",
            " [   0    0    0 1144 4822   96 5948 3865]\n",
            " [   0    0    0 4991 5771  952 7767 1254]\n",
            " [   0    0    0    0 5948 7795 7430 5948]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim = 8\n",
        "# In embedding, we will convert a word into n number of vectors\n",
        "# This will specify as to how many vectors you want the word to be converted"
      ],
      "metadata": {
        "id": "Uh5nR38vv_cM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We neec to create a sequential layer with an embedding layer.\n",
        "# We need to input the vocabulary size, no. of vectors & length of embedded layer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(\n",
        "    input_dim = voc_size,\n",
        "    output_dim = dim,\n",
        "    input_length= 8\n",
        "))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "RCUu1s2o0Cys"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqFpwjZMAec-",
        "outputId": "e0c3a13a-5974-4a55-89ab-cdd0315b3af2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 8, 8)              80000     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 80,000\n",
            "Trainable params: 80,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_wvCt5tAjOd",
        "outputId": "14200ad2-a61b-4630-b22d-6ed6ba7c86f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.00949375, -0.02182547, -0.03836508,  0.02201133,\n",
              "         -0.04275142,  0.03388841, -0.02342689, -0.0284763 ],\n",
              "        [-0.0471159 , -0.01218945, -0.02967845,  0.02938415,\n",
              "          0.02552232, -0.0348387 , -0.00067619, -0.01852181],\n",
              "        [ 0.04766543, -0.01343378, -0.0151849 , -0.04734063,\n",
              "         -0.02773576, -0.02108033,  0.00668893,  0.00026109],\n",
              "        [-0.0474693 ,  0.02347339,  0.00990988, -0.00746365,\n",
              "          0.04408156,  0.01141564, -0.04468708,  0.02919081]],\n",
              "\n",
              "       [[ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.00949375, -0.02182547, -0.03836508,  0.02201133,\n",
              "         -0.04275142,  0.03388841, -0.02342689, -0.0284763 ],\n",
              "        [-0.0471159 , -0.01218945, -0.02967845,  0.02938415,\n",
              "          0.02552232, -0.0348387 , -0.00067619, -0.01852181],\n",
              "        [ 0.04766543, -0.01343378, -0.0151849 , -0.04734063,\n",
              "         -0.02773576, -0.02108033,  0.00668893,  0.00026109],\n",
              "        [-0.02180443,  0.03075004, -0.03881543, -0.00624184,\n",
              "          0.038997  ,  0.02455663, -0.01858924, -0.00253358]],\n",
              "\n",
              "       [[ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.00949375, -0.02182547, -0.03836508,  0.02201133,\n",
              "         -0.04275142,  0.03388841, -0.02342689, -0.0284763 ],\n",
              "        [ 0.01249099, -0.01145183, -0.04050564,  0.01577591,\n",
              "          0.03574467,  0.04714691,  0.03547243, -0.02787375],\n",
              "        [ 0.04766543, -0.01343378, -0.0151849 , -0.04734063,\n",
              "         -0.02773576, -0.02108033,  0.00668893,  0.00026109],\n",
              "        [ 0.03484993,  0.03169237, -0.03625351, -0.01571376,\n",
              "         -0.03407618, -0.02522352,  0.01041011, -0.04113073]],\n",
              "\n",
              "       [[ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [-0.03957114,  0.03598168, -0.01637596, -0.03543943,\n",
              "          0.04023016,  0.03257284, -0.03205276,  0.03707265],\n",
              "        [ 0.02644459,  0.02866817, -0.0367789 , -0.02809265,\n",
              "          0.03361158, -0.04007775,  0.03929743, -0.02817743],\n",
              "        [-0.01407842, -0.0382931 ,  0.04462359, -0.00045333,\n",
              "          0.01265386,  0.04622753, -0.00432005,  0.03744191],\n",
              "        [ 0.03417443, -0.03909488, -0.03993639,  0.02675859,\n",
              "         -0.00437119,  0.01156072,  0.04318294,  0.00942795],\n",
              "        [ 0.02194793,  0.02356483,  0.00891529,  0.02754437,\n",
              "         -0.0420277 , -0.02152263, -0.00974999,  0.04134518]],\n",
              "\n",
              "       [[ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [-0.03957114,  0.03598168, -0.01637596, -0.03543943,\n",
              "          0.04023016,  0.03257284, -0.03205276,  0.03707265],\n",
              "        [ 0.02644459,  0.02866817, -0.0367789 , -0.02809265,\n",
              "          0.03361158, -0.04007775,  0.03929743, -0.02817743],\n",
              "        [-0.01407842, -0.0382931 ,  0.04462359, -0.00045333,\n",
              "          0.01265386,  0.04622753, -0.00432005,  0.03744191],\n",
              "        [ 0.03417443, -0.03909488, -0.03993639,  0.02675859,\n",
              "         -0.00437119,  0.01156072,  0.04318294,  0.00942795],\n",
              "        [-0.02973938, -0.00796789, -0.01230278,  0.01521343,\n",
              "         -0.00458913,  0.04848543, -0.01567511, -0.00102686]],\n",
              "\n",
              "       [[ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.02360505, -0.04022884,  0.02146954,  0.02945003,\n",
              "         -0.03416826, -0.04244823,  0.01097776, -0.01809164],\n",
              "        [ 0.00949375, -0.02182547, -0.03836508,  0.02201133,\n",
              "         -0.04275142,  0.03388841, -0.02342689, -0.0284763 ],\n",
              "        [ 0.04123341,  0.04024979,  0.0262179 ,  0.02685174,\n",
              "         -0.00385191,  0.00392199, -0.00422157,  0.01824056],\n",
              "        [ 0.04766543, -0.01343378, -0.0151849 , -0.04734063,\n",
              "         -0.02773576, -0.02108033,  0.00668893,  0.00026109],\n",
              "        [-0.01953167, -0.02943292, -0.03244021,  0.04086992,\n",
              "          0.00938591, -0.03391681, -0.01075002,  0.0426163 ]],\n",
              "\n",
              "       [[ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.01401231,  0.03912989,  0.02971024,  0.03558644,\n",
              "          0.01310122, -0.04958609, -0.04426647,  0.00912289],\n",
              "        [ 0.03417443, -0.03909488, -0.03993639,  0.02675859,\n",
              "         -0.00437119,  0.01156072,  0.04318294,  0.00942795],\n",
              "        [ 0.03559003, -0.03287172,  0.03486718,  0.04125125,\n",
              "          0.04807614,  0.00485011,  0.0404804 , -0.04508544],\n",
              "        [-0.04987415,  0.04419288, -0.02651714, -0.04347784,\n",
              "          0.03113487, -0.02158886,  0.04934727, -0.04108757],\n",
              "        [ 0.03417443, -0.03909488, -0.03993639,  0.02675859,\n",
              "         -0.00437119,  0.01156072,  0.04318294,  0.00942795]]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_KKNDTtAoq9",
        "outputId": "ab752765-069a-4449-c512-98291aa49ad4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0, 5771, 9952, 7767,  906], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(embedded)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHMYbNVgBSKa",
        "outputId": "1b27834a-69b0-4af9-8c1a-effa213ae2ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02440865, -0.0339918 , -0.03517089,  0.03403086, -0.00674397,\n",
              "         0.0354887 ,  0.03872419,  0.03369043],\n",
              "       [ 0.02440865, -0.0339918 , -0.03517089,  0.03403086, -0.00674397,\n",
              "         0.0354887 ,  0.03872419,  0.03369043],\n",
              "       [ 0.02440865, -0.0339918 , -0.03517089,  0.03403086, -0.00674397,\n",
              "         0.0354887 ,  0.03872419,  0.03369043],\n",
              "       [ 0.02440865, -0.0339918 , -0.03517089,  0.03403086, -0.00674397,\n",
              "         0.0354887 ,  0.03872419,  0.03369043],\n",
              "       [ 0.04996114,  0.01930262, -0.04301338,  0.04000736,  0.02467145,\n",
              "        -0.00122646, -0.01657243,  0.03436524],\n",
              "       [-0.04873593, -0.00293987, -0.0480734 ,  0.01699766,  0.0212618 ,\n",
              "         0.04317651, -0.04058989, -0.03932529],\n",
              "       [-0.04560199,  0.03740123, -0.01367122, -0.02418545,  0.00885201,\n",
              "        -0.01395698,  0.02960006,  0.049202  ],\n",
              "       [-0.03373505,  0.01925254, -0.04943389, -0.02050625,  0.04770286,\n",
              "        -0.02562121, -0.02955829, -0.02621728]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lkDjJjUrBViq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}